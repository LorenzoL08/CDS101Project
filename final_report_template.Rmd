---
title: "CDS 101 â€“ Final Project Report"

author: "Team 3: Athir, Lorenzo, Abel"


date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  html_document:
    css: "gmu-cds101.css"
    toc: true
    toc_depth: 3
    number_sections: true
  pdf_document:
    toc: true
---

> Replace this template text with your own writing, keeping the headings and overall structure aligned with the **CDS 101 project rubric**.

# 1. Problem Definition


Burglary is a crime that is the cause of significant safety and financial concerns for residents of urban areas. Understanding when burglaries are most likely to occur can help our communities, law enforcement, and policymakers better understand and implement preventative measures. The Washington Dc area is a large and densely populated area, making it an important case study for examining certain crimes and patterns of those crimes. 

The main research question for this project is: **Does the frequency of burglary incidents in the DC Metro area differ across different times of day?** The main objective of this project is to use historical crime data to examine how burglary occurrences vary by time of day and to test whether these differences are significant. We assume that reported burglary data accurately shows real crime patterns, and that the time of day classifications are recorded in a consistent way.

To address this research question, we will first load and inspect the DC Metro Crime dataset. We will then clean the data by filtering for burglary offenses and handling missing values in the time of day variable. Next, we will do some exploratory data analysis using summaries and visualizations to examine how burglary frequency varies by shift. Finally, we will perform a formal hypothesis test to determine whether the observed differences across times of day are statistically significant, and interpret the results.


# 2. Data Acquisition & Description

The dataset used for this project is the **DC Metro Crime Dataset**, obtained from Kaggle. It contains records of reported criminal incidents in the Washington, DC metro area.

The dataset was obtained by downloading the CSV file from the Kaggle website and storing it locally in the project data folder for analysis.

Key variables used in this project include:

- **offense (categorical)**: the type of crime committed (for example, burglary).

- **shift (categorical)**: the time of day the crime occurred, categorized as Day, Evening, or Midnight.

The full dataset contains 342,864 observations and 32 variables. Due to GitHub file size limits, the dataset was split into two CSV files, dc_crime_part1.csv and dc_crime_part2.csv, which together is the complete dataset.


This dataset is based on publicly released government crime reports, so it does not contain personal identifying information. However, we believe potential reporting bias may exist, as not all crimes are reported equally across neighborhoods or times. Additionally, policing practices and data collection methods may influence recorded crime frequencies.



```{r setup-data, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)

# We will load both parts of the dataset
dc_part1 <- read.csv("data/dc_crime_part1.csv")
dc_part2 <- read.csv("data/dc_crime_part2.csv")

#combine
dc_crime <- bind_rows(dc_part1,dc_part2)
```

# 3. Data Cleaning & Preprocessing

Before conducting our analysis, the raw DC Metro Crime dataset was cleaned and preprocessed to make sure everything was accurate and consistent.

Records with missing or not valid values in key variables, mainly shift (time of day) and offense, were removed from the dataset. These variables are required for answering the research question, so incomplete values could not be used.

Several variables were converted to appropriate data types:

- **shift** and **offense** were converted to categorical variables.

- **date** and **time-related fields** were formatted into proper date types where needed.
This made sure that grouping, filtering, and tests could be done correctly.

No numerical outliers were removed because the analysis focuses on categorical variables of burglary incidents and not continuous numeric measurements. Every valid burglary report was kept to keep the validity of the crime distribution.

The dataset was filtered to include only burglary offenses, since burglary is the main focus of the research question. This created a new working dataset we used for modeling and hypothesis testing. Additionally, the shift variable was used as the main grouping variable to compare burglary frequency across times of day.

No numeric scaling was required because the analysis does not rely on continuous predictors.


```{r cleaning, eval=FALSE}
library(tidyverse)

#Need to keep only the variables we need
dc_clean <- dc_crime %>%
  select(OFFENSE,SHIFT, REPORT_DAT)

#Need to remove missing values in the variables
dc_clean <- dc_clean %>%
  filter(!is.na(OFFENSE), !is.na(SHIFT))

#Now we need to convert the data types
dc_clean <- dc_clean %>%
  mutate(
    OFFENSE = as.factor(OFFENSE),
    SHIFT = as.factor(SHIFT),
    REPORT_DAT = as.Date(REPORT_DAT, format = "%m/%d/%Y")
  )

#Now we filter for Burglary only
dc_burglary <- dc_clean %>%
  filter(OFFENSE == "BURGLARY")
```

# 4. Exploratory Data Analysis (EDA)

This section maps directly to the **EDA** part of the rubric:

- Summary statistics  
- Visualizations  
- Interpretation connected to the research question  

```{r eda-summary, message=FALSE, warning=FALSE}
# library(dplyr)
# summary(data_clean)
```

```{r eda-plot-example, message=FALSE, warning=FALSE, fig.cap="Example histogram of a numeric variable (EDA rubric)."}
# library(ggplot2)
# ggplot(data_clean, aes(x = some_numeric_variable)) +
#   geom_histogram(binwidth = 5, color = "white") +
#   labs(x = "Some Variable", y = "Count", title = "Distribution of Some Variable")
```

# 5. Visualization Quality and Storytelling

Use this section to satisfy the **Visualization Quality** rubric criterion:

- Explain why your plot types are appropriate.  
- Comment on labels, legends, colors, and overall readability.  
- Mention any steps you took to make plots accessible and interpretable.

# 6. Modeling Approach

Explain how you framed the problem and which models you chose:

- Type of task (regression, classification, etc.).  
- Baseline model or heuristic, if used.  
- Main model(s) chosen and why they are appropriate.

# 7. Model Implementation & Evaluation

This corresponds to the **Model Implementation & Evaluation** rubric criterion.

Describe:

- Features used.  
- Data splitting strategy (train/test or cross-validation).  
- Metrics used (accuracy, F1, RMSE, etc.).  
- Tables/plots summarizing performance.  
- A short interpretation of each metric/plot.

```{r modeling, eval=FALSE}
# Example structure:
# set.seed(123)
# train_index <- sample(seq_len(nrow(data_clean)), size = 0.8 * nrow(data_clean))
# train <- data_clean[train_index, ]
# test  <- data_clean[-train_index, ]
#
# model <- glm(target ~ ., data = train, family = binomial)
# preds <- predict(model, newdata = test, type = "response")
# # compute metrics...
```

# 8. Conclusions & Recommendations

Summarize the key takeaways:

- Answer your original research question(s) directly.  
- Highlight the most important patterns or relationships you found.  
- Discuss limitations (data size, bias, missing variables, etc.).  
- Suggest possible extensions or future work.

# 9. Code Quality & Reproducibility

Briefly document how someone else can reproduce your results:

- Which R scripts or Rmd files to run.  
- Any required R packages.  

```{r session-info, echo=FALSE}
sessionInfo()
```

# 10. References

List any references you used, such as:

- Dataset documentation.  
- Research papers or articles.  
- Tutorials or blog posts.

# Appendix (Optional)

Include extra plots, diagnostic checks, or model comparisons if needed.
